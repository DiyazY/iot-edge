apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-03-08T09:56:10Z"
    labels:
      app: kbench
      name: myredisserverclient
      opnum: "0"
      podtype: redisworker
      tid: "0"
      type: kbench-pod
    name: kbench-pod-oid-0-tid-0
    namespace: kbench-pod-namespace
    resourceVersion: "213235"
    uid: 41790c76-9e0b-45bd-9c04-97cf438dbc2c
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: my.kubernetes.io/instance-type
              operator: In
              values:
              - worker
    containers:
    - args:
      - apt-get update; apt-get install -y redis-server; apt-get install -y git libssl-dev
        build-essential autoconf automake libpcre3-dev libevent-dev pkg-config zlib1g-dev;
        cd /; git clone https://github.com/RedisLabs/memtier_benchmark.git; cd /memtier_benchmark/;
        autoreconf -ivf; ./configure; make; sleep infinity;
      command:
      - /bin/sh
      - -c
      image: nginx
      imagePullPolicy: Always
      name: rediscontainer
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-75nmr
        readOnly: true
    dnsPolicy: ClusterFirstWithHostNet
    enableServiceLinks: true
    hostNetwork: true
    nodeName: ubuntu-host-a6773f
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-75nmr
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T09:56:10Z"
      status: "False"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T09:56:10Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T09:56:10Z"
      message: 'containers with unready status: [rediscontainer]'
      reason: ContainersNotReady
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T09:56:10Z"
      message: 'containers with unready status: [rediscontainer]'
      reason: ContainersNotReady
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T09:56:10Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - image: nginx
      imageID: ""
      lastState: {}
      name: rediscontainer
      ready: false
      restartCount: 0
      started: false
      state:
        waiting:
          reason: ContainerCreating
    hostIP: 192.168.1.102
    hostIPs:
    - ip: 192.168.1.102
    phase: Pending
    podIP: 192.168.1.102
    podIPs:
    - ip: 192.168.1.102
    qosClass: BestEffort
    startTime: "2024-03-08T09:56:10Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-03-08T09:56:10Z"
    labels:
      app: kbench
      name: myredisserverclient
      opnum: "0"
      podtype: redisworker
      tid: "1"
      type: kbench-pod
    name: kbench-pod-oid-0-tid-1
    namespace: kbench-pod-namespace
    resourceVersion: "213232"
    uid: 94a7c6b5-7755-4e04-833c-38a6a38a2cb4
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: my.kubernetes.io/instance-type
              operator: In
              values:
              - worker
    containers:
    - args:
      - apt-get update; apt-get install -y redis-server; apt-get install -y git libssl-dev
        build-essential autoconf automake libpcre3-dev libevent-dev pkg-config zlib1g-dev;
        cd /; git clone https://github.com/RedisLabs/memtier_benchmark.git; cd /memtier_benchmark/;
        autoreconf -ivf; ./configure; make; sleep infinity;
      command:
      - /bin/sh
      - -c
      image: nginx
      imagePullPolicy: Always
      name: rediscontainer
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-6r75h
        readOnly: true
    dnsPolicy: ClusterFirstWithHostNet
    enableServiceLinks: true
    hostNetwork: true
    nodeName: ubuntu-host-76d48b
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-6r75h
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T09:56:10Z"
      status: "False"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T09:56:10Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T09:56:10Z"
      message: 'containers with unready status: [rediscontainer]'
      reason: ContainersNotReady
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T09:56:10Z"
      message: 'containers with unready status: [rediscontainer]'
      reason: ContainersNotReady
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T09:56:10Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - image: nginx
      imageID: ""
      lastState: {}
      name: rediscontainer
      ready: false
      restartCount: 0
      started: false
      state:
        waiting:
          reason: ContainerCreating
    hostIP: 192.168.1.101
    hostIPs:
    - ip: 192.168.1.101
    phase: Pending
    podIP: 192.168.1.101
    podIPs:
    - ip: 192.168.1.101
    qosClass: BestEffort
    startTime: "2024-03-08T09:56:10Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-03-08T09:56:10Z"
    labels:
      app: kbench
      name: myredisserverclient
      opnum: "0"
      podtype: redisworker
      tid: "2"
      type: kbench-pod
    name: kbench-pod-oid-0-tid-2
    namespace: kbench-pod-namespace
    resourceVersion: "213234"
    uid: 3c47c684-332d-480d-b07a-936e4bc0a69c
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: my.kubernetes.io/instance-type
              operator: In
              values:
              - worker
    containers:
    - args:
      - apt-get update; apt-get install -y redis-server; apt-get install -y git libssl-dev
        build-essential autoconf automake libpcre3-dev libevent-dev pkg-config zlib1g-dev;
        cd /; git clone https://github.com/RedisLabs/memtier_benchmark.git; cd /memtier_benchmark/;
        autoreconf -ivf; ./configure; make; sleep infinity;
      command:
      - /bin/sh
      - -c
      image: nginx
      imagePullPolicy: Always
      name: rediscontainer
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-p92vv
        readOnly: true
    dnsPolicy: ClusterFirstWithHostNet
    enableServiceLinks: true
    hostNetwork: true
    nodeName: ubuntu-host-75e4c5
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-p92vv
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T09:56:10Z"
      status: "False"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T09:56:10Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T09:56:10Z"
      message: 'containers with unready status: [rediscontainer]'
      reason: ContainersNotReady
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T09:56:10Z"
      message: 'containers with unready status: [rediscontainer]'
      reason: ContainersNotReady
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T09:56:10Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - image: nginx
      imageID: ""
      lastState: {}
      name: rediscontainer
      ready: false
      restartCount: 0
      started: false
      state:
        waiting:
          reason: ContainerCreating
    hostIP: 192.168.1.100
    hostIPs:
    - ip: 192.168.1.100
    phase: Pending
    podIP: 192.168.1.100
    podIPs:
    - ip: 192.168.1.100
    qosClass: BestEffort
    startTime: "2024-03-08T09:56:10Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-03-06T19:54:32Z"
    generateName: kube-flannel-ds-
    labels:
      app: flannel
      controller-revision-hash: 655c87b4c5
      k8s-app: flannel
      pod-template-generation: "1"
      tier: node
    name: kube-flannel-ds-86r28
    namespace: kube-flannel
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-flannel-ds
      uid: 423cf737-db9a-4d60-9b62-e52dce100d67
    resourceVersion: "196340"
    uid: adea6cb2-187f-4bdd-a456-09f9b2bc667d
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ubuntu-host-75e4c5
    containers:
    - args:
      - --ip-masq
      - --kube-subnet-mgr
      command:
      - /opt/bin/flanneld
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: EVENT_QUEUE_DEPTH
        value: "5000"
      image: docker.io/flannel/flannel:v0.24.3
      imagePullPolicy: IfNotPresent
      name: kube-flannel
      resources:
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        capabilities:
          add:
          - NET_ADMIN
          - NET_RAW
        privileged: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /run/flannel
        name: run
      - mountPath: /etc/kube-flannel/
        name: flannel-cfg
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-vz2xh
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - args:
      - -f
      - /flannel
      - /opt/cni/bin/flannel
      command:
      - cp
      image: docker.io/flannel/flannel-cni-plugin:v1.4.0-flannel1
      imagePullPolicy: IfNotPresent
      name: install-cni-plugin
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /opt/cni/bin
        name: cni-plugin
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-vz2xh
        readOnly: true
    - args:
      - -f
      - /etc/kube-flannel/cni-conf.json
      - /etc/cni/net.d/10-flannel.conflist
      command:
      - cp
      image: docker.io/flannel/flannel:v0.24.3
      imagePullPolicy: IfNotPresent
      name: install-cni
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/cni/net.d
        name: cni
      - mountPath: /etc/kube-flannel/
        name: flannel-cfg
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-vz2xh
        readOnly: true
    nodeName: ubuntu-host-75e4c5
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: flannel
    serviceAccountName: flannel
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /run/flannel
        type: ""
      name: run
    - hostPath:
        path: /opt/cni/bin
        type: ""
      name: cni-plugin
    - hostPath:
        path: /etc/cni/net.d
        type: ""
      name: cni
    - configMap:
        defaultMode: 420
        name: kube-flannel-cfg
      name: flannel-cfg
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - name: kube-api-access-vz2xh
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:57:06Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-03-06T19:55:14Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:57:22Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:57:22Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-06T19:54:32Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://a63645410f7e4ada89029cd44430fc253244a5557cf8a4a4750988525d1a9cdf
      image: docker.io/flannel/flannel:v0.24.3
      imageID: docker.io/flannel/flannel@sha256:452061a392663283672e905be10762e142d7ad6126ddee7b772e14405ee79a6a
      lastState:
        terminated:
          containerID: containerd://0d8d2e702dadf7c0a4ea4a338960f90b9d4c34ba349784e76901a75b0e1665a1
          exitCode: 255
          finishedAt: "2023-09-19T17:00:05Z"
          reason: Unknown
          startedAt: "2024-03-06T19:55:14Z"
      name: kube-flannel
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-03-08T06:57:22Z"
    hostIP: 192.168.1.100
    hostIPs:
    - ip: 192.168.1.100
    initContainerStatuses:
    - containerID: containerd://cd17f5e06eb4c867cf4636413d52e26d6de3ffb10000b954d2f375508de8fc89
      image: docker.io/flannel/flannel-cni-plugin:v1.4.0-flannel1
      imageID: docker.io/flannel/flannel-cni-plugin@sha256:743c25e5e477527d8e54faa3e5259fbbee3463a335de1690879fc74305edc79b
      lastState: {}
      name: install-cni-plugin
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://cd17f5e06eb4c867cf4636413d52e26d6de3ffb10000b954d2f375508de8fc89
          exitCode: 0
          finishedAt: "2024-03-08T06:57:19Z"
          reason: Completed
          startedAt: "2024-03-08T06:57:18Z"
    - containerID: containerd://649f6a3fa6918a5e2625f0dc92d0c1e00613e91bb81606c23a5f78e68e284ec9
      image: docker.io/flannel/flannel:v0.24.3
      imageID: docker.io/flannel/flannel@sha256:452061a392663283672e905be10762e142d7ad6126ddee7b772e14405ee79a6a
      lastState: {}
      name: install-cni
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://649f6a3fa6918a5e2625f0dc92d0c1e00613e91bb81606c23a5f78e68e284ec9
          exitCode: 0
          finishedAt: "2024-03-08T06:57:21Z"
          reason: Completed
          startedAt: "2024-03-08T06:57:21Z"
    phase: Running
    podIP: 192.168.1.100
    podIPs:
    - ip: 192.168.1.100
    qosClass: Burstable
    startTime: "2024-03-06T19:54:33Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-03-06T19:55:54Z"
    generateName: kube-flannel-ds-
    labels:
      app: flannel
      controller-revision-hash: 655c87b4c5
      k8s-app: flannel
      pod-template-generation: "1"
      tier: node
    name: kube-flannel-ds-bgn66
    namespace: kube-flannel
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-flannel-ds
      uid: 423cf737-db9a-4d60-9b62-e52dce100d67
    resourceVersion: "196353"
    uid: 72e3a8d4-a2ac-4187-944d-fbdf1aad5a2e
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ubuntu-host-76d48b
    containers:
    - args:
      - --ip-masq
      - --kube-subnet-mgr
      command:
      - /opt/bin/flanneld
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: EVENT_QUEUE_DEPTH
        value: "5000"
      image: docker.io/flannel/flannel:v0.24.3
      imagePullPolicy: IfNotPresent
      name: kube-flannel
      resources:
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        capabilities:
          add:
          - NET_ADMIN
          - NET_RAW
        privileged: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /run/flannel
        name: run
      - mountPath: /etc/kube-flannel/
        name: flannel-cfg
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-t64wd
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - args:
      - -f
      - /flannel
      - /opt/cni/bin/flannel
      command:
      - cp
      image: docker.io/flannel/flannel-cni-plugin:v1.4.0-flannel1
      imagePullPolicy: IfNotPresent
      name: install-cni-plugin
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /opt/cni/bin
        name: cni-plugin
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-t64wd
        readOnly: true
    - args:
      - -f
      - /etc/kube-flannel/cni-conf.json
      - /etc/cni/net.d/10-flannel.conflist
      command:
      - cp
      image: docker.io/flannel/flannel:v0.24.3
      imagePullPolicy: IfNotPresent
      name: install-cni
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/cni/net.d
        name: cni
      - mountPath: /etc/kube-flannel/
        name: flannel-cfg
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-t64wd
        readOnly: true
    nodeName: ubuntu-host-76d48b
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: flannel
    serviceAccountName: flannel
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /run/flannel
        type: ""
      name: run
    - hostPath:
        path: /opt/cni/bin
        type: ""
      name: cni-plugin
    - hostPath:
        path: /etc/cni/net.d
        type: ""
      name: cni
    - configMap:
        defaultMode: 420
        name: kube-flannel-cfg
      name: flannel-cfg
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - name: kube-api-access-t64wd
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:57:06Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-03-06T19:56:52Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:57:25Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:57:25Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-06T19:55:55Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://c56c4fea53819f20276da15e0f4308ad0c0c9a7e8b9e0b01fce3ee8925730947
      image: docker.io/flannel/flannel:v0.24.3
      imageID: docker.io/flannel/flannel@sha256:452061a392663283672e905be10762e142d7ad6126ddee7b772e14405ee79a6a
      lastState:
        terminated:
          containerID: containerd://d43be11ca65e60caa95cf5799b3f49f827d107c53de4f9c0eab2a236a36b9148
          exitCode: 255
          finishedAt: "2023-09-19T17:00:07Z"
          reason: Unknown
          startedAt: "2024-03-06T19:56:52Z"
      name: kube-flannel
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-03-08T06:57:24Z"
    hostIP: 192.168.1.101
    hostIPs:
    - ip: 192.168.1.101
    initContainerStatuses:
    - containerID: containerd://51b19b1f9b311e6e48b2cc992c83dc1c4329b3042ac867be3675f224c1ccc8e4
      image: docker.io/flannel/flannel-cni-plugin:v1.4.0-flannel1
      imageID: docker.io/flannel/flannel-cni-plugin@sha256:743c25e5e477527d8e54faa3e5259fbbee3463a335de1690879fc74305edc79b
      lastState: {}
      name: install-cni-plugin
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://51b19b1f9b311e6e48b2cc992c83dc1c4329b3042ac867be3675f224c1ccc8e4
          exitCode: 0
          finishedAt: "2024-03-08T06:57:20Z"
          reason: Completed
          startedAt: "2024-03-08T06:57:20Z"
    - containerID: containerd://cd2683b3b902150e9ded600f538c013576f3ab1eae50a002d8195d33be6d40b8
      image: docker.io/flannel/flannel:v0.24.3
      imageID: docker.io/flannel/flannel@sha256:452061a392663283672e905be10762e142d7ad6126ddee7b772e14405ee79a6a
      lastState: {}
      name: install-cni
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://cd2683b3b902150e9ded600f538c013576f3ab1eae50a002d8195d33be6d40b8
          exitCode: 0
          finishedAt: "2024-03-08T06:57:23Z"
          reason: Completed
          startedAt: "2024-03-08T06:57:22Z"
    phase: Running
    podIP: 192.168.1.101
    podIPs:
    - ip: 192.168.1.101
    qosClass: Burstable
    startTime: "2024-03-06T19:55:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-03-06T19:49:35Z"
    generateName: kube-flannel-ds-
    labels:
      app: flannel
      controller-revision-hash: 655c87b4c5
      k8s-app: flannel
      pod-template-generation: "1"
      tier: node
    name: kube-flannel-ds-nsb2x
    namespace: kube-flannel
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-flannel-ds
      uid: 423cf737-db9a-4d60-9b62-e52dce100d67
    resourceVersion: "196151"
    uid: 2465b70a-10bf-414e-b1d3-c371a8185af3
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ubuntu-host-ddde9b
    containers:
    - args:
      - --ip-masq
      - --kube-subnet-mgr
      command:
      - /opt/bin/flanneld
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: EVENT_QUEUE_DEPTH
        value: "5000"
      image: docker.io/flannel/flannel:v0.24.3
      imagePullPolicy: IfNotPresent
      name: kube-flannel
      resources:
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        capabilities:
          add:
          - NET_ADMIN
          - NET_RAW
        privileged: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /run/flannel
        name: run
      - mountPath: /etc/kube-flannel/
        name: flannel-cfg
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9qgkc
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - args:
      - -f
      - /flannel
      - /opt/cni/bin/flannel
      command:
      - cp
      image: docker.io/flannel/flannel-cni-plugin:v1.4.0-flannel1
      imagePullPolicy: IfNotPresent
      name: install-cni-plugin
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /opt/cni/bin
        name: cni-plugin
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9qgkc
        readOnly: true
    - args:
      - -f
      - /etc/kube-flannel/cni-conf.json
      - /etc/cni/net.d/10-flannel.conflist
      command:
      - cp
      image: docker.io/flannel/flannel:v0.24.3
      imagePullPolicy: IfNotPresent
      name: install-cni
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/cni/net.d
        name: cni
      - mountPath: /etc/kube-flannel/
        name: flannel-cfg
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9qgkc
        readOnly: true
    nodeName: ubuntu-host-ddde9b
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: flannel
    serviceAccountName: flannel
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /run/flannel
        type: ""
      name: run
    - hostPath:
        path: /opt/cni/bin
        type: ""
      name: cni-plugin
    - hostPath:
        path: /etc/cni/net.d
        type: ""
      name: cni
    - configMap:
        defaultMode: 420
        name: kube-flannel-cfg
      name: flannel-cfg
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - name: kube-api-access-9qgkc
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:56:43Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-03-06T19:49:44Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:56:45Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:56:45Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-06T19:49:35Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://518f679cdc7486e4f8f07400c846f975dd9f0ec81165deb5ef5ff7bfaacf490b
      image: docker.io/flannel/flannel:v0.24.3
      imageID: docker.io/flannel/flannel@sha256:452061a392663283672e905be10762e142d7ad6126ddee7b772e14405ee79a6a
      lastState:
        terminated:
          containerID: containerd://26d945ae74199b52d187b937162f580f0d94c5fe3a814bfccbb483d0a5ada1b0
          exitCode: 255
          finishedAt: "2024-03-08T06:53:39Z"
          reason: Unknown
          startedAt: "2024-03-06T19:49:44Z"
      name: kube-flannel
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-03-08T06:56:44Z"
    hostIP: 192.168.1.106
    hostIPs:
    - ip: 192.168.1.106
    initContainerStatuses:
    - containerID: containerd://1b94adbf4507e62b6ac0f9e2d217d3dca31e688038792dbc8af4f2536942c5a7
      image: docker.io/flannel/flannel-cni-plugin:v1.4.0-flannel1
      imageID: docker.io/flannel/flannel-cni-plugin@sha256:743c25e5e477527d8e54faa3e5259fbbee3463a335de1690879fc74305edc79b
      lastState: {}
      name: install-cni-plugin
      ready: true
      restartCount: 1
      started: false
      state:
        terminated:
          containerID: containerd://1b94adbf4507e62b6ac0f9e2d217d3dca31e688038792dbc8af4f2536942c5a7
          exitCode: 0
          finishedAt: "2024-03-08T06:56:42Z"
          reason: Completed
          startedAt: "2024-03-08T06:56:42Z"
    - containerID: containerd://f38eb434855f34e7b7ff0f77cd789a092ea45328f04cf5ed70b49d33addbddd6
      image: docker.io/flannel/flannel:v0.24.3
      imageID: docker.io/flannel/flannel@sha256:452061a392663283672e905be10762e142d7ad6126ddee7b772e14405ee79a6a
      lastState: {}
      name: install-cni
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://f38eb434855f34e7b7ff0f77cd789a092ea45328f04cf5ed70b49d33addbddd6
          exitCode: 0
          finishedAt: "2024-03-08T06:56:43Z"
          reason: Completed
          startedAt: "2024-03-08T06:56:43Z"
    phase: Running
    podIP: 192.168.1.106
    podIPs:
    - ip: 192.168.1.106
    qosClass: Burstable
    startTime: "2024-03-06T19:49:35Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-03-06T20:01:19Z"
    generateName: kube-flannel-ds-
    labels:
      app: flannel
      controller-revision-hash: 655c87b4c5
      k8s-app: flannel
      pod-template-generation: "1"
      tier: node
    name: kube-flannel-ds-q2gcn
    namespace: kube-flannel
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-flannel-ds
      uid: 423cf737-db9a-4d60-9b62-e52dce100d67
    resourceVersion: "196292"
    uid: ab2c3806-0bbb-4faa-bd97-610b0a98af34
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ubuntu-host-a6773f
    containers:
    - args:
      - --ip-masq
      - --kube-subnet-mgr
      command:
      - /opt/bin/flanneld
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: EVENT_QUEUE_DEPTH
        value: "5000"
      image: docker.io/flannel/flannel:v0.24.3
      imagePullPolicy: IfNotPresent
      name: kube-flannel
      resources:
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        capabilities:
          add:
          - NET_ADMIN
          - NET_RAW
        privileged: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /run/flannel
        name: run
      - mountPath: /etc/kube-flannel/
        name: flannel-cfg
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xcfrr
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - args:
      - -f
      - /flannel
      - /opt/cni/bin/flannel
      command:
      - cp
      image: docker.io/flannel/flannel-cni-plugin:v1.4.0-flannel1
      imagePullPolicy: IfNotPresent
      name: install-cni-plugin
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /opt/cni/bin
        name: cni-plugin
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xcfrr
        readOnly: true
    - args:
      - -f
      - /etc/kube-flannel/cni-conf.json
      - /etc/cni/net.d/10-flannel.conflist
      command:
      - cp
      image: docker.io/flannel/flannel:v0.24.3
      imagePullPolicy: IfNotPresent
      name: install-cni
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/cni/net.d
        name: cni
      - mountPath: /etc/kube-flannel/
        name: flannel-cfg
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xcfrr
        readOnly: true
    nodeName: ubuntu-host-a6773f
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: flannel
    serviceAccountName: flannel
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /run/flannel
        type: ""
      name: run
    - hostPath:
        path: /opt/cni/bin
        type: ""
      name: cni-plugin
    - hostPath:
        path: /etc/cni/net.d
        type: ""
      name: cni
    - configMap:
        defaultMode: 420
        name: kube-flannel-cfg
      name: flannel-cfg
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - name: kube-api-access-xcfrr
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:57:09Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-03-06T20:02:10Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:57:14Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:57:14Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-06T20:01:19Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://b7fbfd703f3f21c26bfb3eaeab7639dbe3181c4139242db7d85393ec6361d9ed
      image: docker.io/flannel/flannel:v0.24.3
      imageID: docker.io/flannel/flannel@sha256:452061a392663283672e905be10762e142d7ad6126ddee7b772e14405ee79a6a
      lastState:
        terminated:
          containerID: containerd://7943ada74ce779e53af85d18bfd6b32f4018fda264e883d0dd365ef257344be7
          exitCode: 255
          finishedAt: "2023-09-19T17:00:04Z"
          reason: Unknown
          startedAt: "2024-03-06T20:02:11Z"
      name: kube-flannel
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-03-08T06:57:13Z"
    hostIP: 192.168.1.102
    hostIPs:
    - ip: 192.168.1.102
    initContainerStatuses:
    - containerID: containerd://ebec501b673d6b92ee8e66d6e4e6e9b0c0a8a5114972b6f5263472324ca193b5
      image: docker.io/flannel/flannel-cni-plugin:v1.4.0-flannel1
      imageID: docker.io/flannel/flannel-cni-plugin@sha256:743c25e5e477527d8e54faa3e5259fbbee3463a335de1690879fc74305edc79b
      lastState: {}
      name: install-cni-plugin
      ready: true
      restartCount: 1
      started: false
      state:
        terminated:
          containerID: containerd://ebec501b673d6b92ee8e66d6e4e6e9b0c0a8a5114972b6f5263472324ca193b5
          exitCode: 0
          finishedAt: "2024-03-08T06:57:09Z"
          reason: Completed
          startedAt: "2024-03-08T06:57:09Z"
    - containerID: containerd://de91437550523d9ce67beb979476f29c28710cf6872325180f2fe5c22a35797f
      image: docker.io/flannel/flannel:v0.24.3
      imageID: docker.io/flannel/flannel@sha256:452061a392663283672e905be10762e142d7ad6126ddee7b772e14405ee79a6a
      lastState: {}
      name: install-cni
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://de91437550523d9ce67beb979476f29c28710cf6872325180f2fe5c22a35797f
          exitCode: 0
          finishedAt: "2024-03-08T06:57:11Z"
          reason: Completed
          startedAt: "2024-03-08T06:57:11Z"
    phase: Running
    podIP: 192.168.1.102
    podIPs:
    - ip: 192.168.1.102
    qosClass: Burstable
    startTime: "2024-03-06T20:01:20Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-03-06T19:34:09Z"
    generateName: coredns-76f75df574-
    labels:
      k8s-app: kube-dns
      pod-template-hash: 76f75df574
    name: coredns-76f75df574-pkmbt
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: coredns-76f75df574
      uid: 4eb85c37-d82e-4b19-9434-ba01cbb04931
    resourceVersion: "208376"
    uid: 8ac868d2-5312-4acc-a96e-5cb353946341
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: k8s-app
                operator: In
                values:
                - kube-dns
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      image: registry.k8s.io/coredns/coredns:v1.11.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: coredns
      ports:
      - containerPort: 53
        name: dns
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      - containerPort: 9153
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-cmkh5
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: ubuntu-host-ddde9b
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: coredns
    serviceAccountName: coredns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        name: coredns
      name: config-volume
    - name: kube-api-access-cmkh5
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:56:52Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-03-06T19:49:58Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T09:05:41Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T09:05:41Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-06T19:49:58Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://110adc0028fbd5420cdd97e1f7c8bdd9fdb3eb4fd30ed1caa9d9ce015b632fe3
      image: registry.k8s.io/coredns/coredns:v1.11.1
      imageID: registry.k8s.io/coredns/coredns@sha256:1eeb4c7316bacb1d4c8ead65571cd92dd21e27359f0d4917f1a5822a73b75db1
      lastState:
        terminated:
          containerID: containerd://667b98e4fab08aa1bfc4c8c528ce27d7ca0575445c2939690c83f4a88911ffb3
          exitCode: 0
          finishedAt: "2024-03-08T09:04:07Z"
          reason: Completed
          startedAt: "2024-03-08T08:27:37Z"
      name: coredns
      ready: true
      restartCount: 34
      started: true
      state:
        running:
          startedAt: "2024-03-08T09:04:07Z"
    hostIP: 192.168.1.106
    hostIPs:
    - ip: 192.168.1.106
    phase: Running
    podIP: 10.244.0.5
    podIPs:
    - ip: 10.244.0.5
    qosClass: Burstable
    startTime: "2024-03-06T19:49:58Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-03-06T19:34:09Z"
    generateName: coredns-76f75df574-
    labels:
      k8s-app: kube-dns
      pod-template-hash: 76f75df574
    name: coredns-76f75df574-zmjkv
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: coredns-76f75df574
      uid: 4eb85c37-d82e-4b19-9434-ba01cbb04931
    resourceVersion: "208369"
    uid: 898921bd-576f-4000-92e3-d059d0ad0b8e
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: k8s-app
                operator: In
                values:
                - kube-dns
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      image: registry.k8s.io/coredns/coredns:v1.11.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: coredns
      ports:
      - containerPort: 53
        name: dns
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      - containerPort: 9153
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-p657d
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: ubuntu-host-ddde9b
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: coredns
    serviceAccountName: coredns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        name: coredns
      name: config-volume
    - name: kube-api-access-p657d
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:56:51Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-03-06T19:49:58Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T09:05:40Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T09:05:40Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-06T19:49:58Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://0048df8a89979ab342e0d1dc68e573c2436bda783a17d3ea96b17b461e12d8e0
      image: registry.k8s.io/coredns/coredns:v1.11.1
      imageID: registry.k8s.io/coredns/coredns@sha256:1eeb4c7316bacb1d4c8ead65571cd92dd21e27359f0d4917f1a5822a73b75db1
      lastState:
        terminated:
          containerID: containerd://75c8d79fe25a64091acff96eb92c7c933c2aebf41f797caf5422131a850e8ca0
          exitCode: 0
          finishedAt: "2024-03-08T09:04:09Z"
          reason: Completed
          startedAt: "2024-03-08T08:27:29Z"
      name: coredns
      ready: true
      restartCount: 34
      started: true
      state:
        running:
          startedAt: "2024-03-08T09:04:09Z"
    hostIP: 192.168.1.106
    hostIPs:
    - ip: 192.168.1.106
    phase: Running
    podIP: 10.244.0.4
    podIPs:
    - ip: 10.244.0.4
    qosClass: Burstable
    startTime: "2024-03-06T19:49:58Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubeadm.kubernetes.io/etcd.advertise-client-urls: https://192.168.1.106:2379
      kubernetes.io/config.hash: 18bdb5bd0135b72d2ccca31748783ae6
      kubernetes.io/config.mirror: 18bdb5bd0135b72d2ccca31748783ae6
      kubernetes.io/config.seen: "2024-03-06T21:33:49.229093995+02:00"
      kubernetes.io/config.source: file
    creationTimestamp: "2024-03-06T19:33:53Z"
    labels:
      component: etcd
      tier: control-plane
    name: etcd-ubuntu-host-ddde9b
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: ubuntu-host-ddde9b
      uid: 8eff4828-5f42-4bc0-a791-84bcdac7502e
    resourceVersion: "196200"
    uid: 90338da2-3f33-49fa-867a-6e5efeed4d93
  spec:
    containers:
    - command:
      - etcd
      - --advertise-client-urls=https://192.168.1.106:2379
      - --cert-file=/etc/kubernetes/pki/etcd/server.crt
      - --client-cert-auth=true
      - --data-dir=/var/lib/etcd
      - --experimental-initial-corrupt-check=true
      - --experimental-watch-progress-notify-interval=5s
      - --initial-advertise-peer-urls=https://192.168.1.106:2380
      - --initial-cluster=ubuntu-host-ddde9b=https://192.168.1.106:2380
      - --key-file=/etc/kubernetes/pki/etcd/server.key
      - --listen-client-urls=https://127.0.0.1:2379,https://192.168.1.106:2379
      - --listen-metrics-urls=http://127.0.0.1:2381
      - --listen-peer-urls=https://192.168.1.106:2380
      - --name=ubuntu-host-ddde9b
      - --peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt
      - --peer-client-cert-auth=true
      - --peer-key-file=/etc/kubernetes/pki/etcd/peer.key
      - --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt
      - --snapshot-count=10000
      - --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt
      image: registry.k8s.io/etcd:3.5.10-0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /health?exclude=NOSPACE&serializable=true
          port: 2381
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: etcd
      resources:
        requests:
          cpu: 100m
          memory: 100Mi
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 127.0.0.1
          path: /health?serializable=false
          port: 2381
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/etcd
        name: etcd-data
      - mountPath: /etc/kubernetes/pki/etcd
        name: etcd-certs
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: ubuntu-host-ddde9b
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/pki/etcd
        type: DirectoryOrCreate
      name: etcd-certs
    - hostPath:
        path: /var/lib/etcd
        type: DirectoryOrCreate
      name: etcd-data
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:56:39Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:56:38Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:56:53Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:56:53Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:56:38Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://f7880206d69ba9c226e0f801c00f11d409982b420fc4077fe67b7e363b4cffcd
      image: registry.k8s.io/etcd:3.5.10-0
      imageID: registry.k8s.io/etcd@sha256:22f892d7672adc0b9c86df67792afdb8b2dc08880f49f669eaaa59c47d7908c2
      lastState:
        terminated:
          containerID: containerd://d1a60ee04fa0333c9387d07a667f986ea6d5a15f4ce75744d7d4d85ca44a9aab
          exitCode: 255
          finishedAt: "2024-03-08T06:53:39Z"
          reason: Unknown
          startedAt: "2024-03-06T19:45:58Z"
      name: etcd
      ready: true
      restartCount: 11
      started: true
      state:
        running:
          startedAt: "2024-03-08T06:56:38Z"
    hostIP: 192.168.1.106
    hostIPs:
    - ip: 192.168.1.106
    phase: Running
    podIP: 192.168.1.106
    podIPs:
    - ip: 192.168.1.106
    qosClass: Burstable
    startTime: "2024-03-08T06:56:38Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubeadm.kubernetes.io/kube-apiserver.advertise-address.endpoint: 192.168.1.106:6443
      kubernetes.io/config.hash: 0448e241a9cd75a937ceb9ab1d0eece7
      kubernetes.io/config.mirror: 0448e241a9cd75a937ceb9ab1d0eece7
      kubernetes.io/config.seen: "2024-03-06T21:33:49.229088527+02:00"
      kubernetes.io/config.source: file
    creationTimestamp: "2024-03-06T19:33:54Z"
    labels:
      component: kube-apiserver
      tier: control-plane
    name: kube-apiserver-ubuntu-host-ddde9b
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: ubuntu-host-ddde9b
      uid: 8eff4828-5f42-4bc0-a791-84bcdac7502e
    resourceVersion: "208322"
    uid: e8c4ae78-eaab-4b18-90fb-9aa67dadff79
  spec:
    containers:
    - command:
      - kube-apiserver
      - --advertise-address=192.168.1.106
      - --allow-privileged=true
      - --authorization-mode=Node,RBAC
      - --client-ca-file=/etc/kubernetes/pki/ca.crt
      - --enable-admission-plugins=NodeRestriction
      - --enable-bootstrap-token-auth=true
      - --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt
      - --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt
      - --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key
      - --etcd-servers=https://127.0.0.1:2379
      - --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt
      - --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key
      - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
      - --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt
      - --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key
      - --requestheader-allowed-names=front-proxy-client
      - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
      - --requestheader-extra-headers-prefix=X-Remote-Extra-
      - --requestheader-group-headers=X-Remote-Group
      - --requestheader-username-headers=X-Remote-User
      - --secure-port=6443
      - --service-account-issuer=https://kubernetes.default.svc.cluster.local
      - --service-account-key-file=/etc/kubernetes/pki/sa.pub
      - --service-account-signing-key-file=/etc/kubernetes/pki/sa.key
      - --service-cluster-ip-range=10.96.0.0/12
      - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt
      - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key
      image: registry.k8s.io/kube-apiserver:v1.29.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 192.168.1.106
          path: /livez
          port: 6443
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-apiserver
      readinessProbe:
        failureThreshold: 3
        httpGet:
          host: 192.168.1.106
          path: /readyz
          port: 6443
          scheme: HTTPS
        periodSeconds: 1
        successThreshold: 1
        timeoutSeconds: 15
      resources:
        requests:
          cpu: 250m
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 192.168.1.106
          path: /livez
          port: 6443
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: ca-certs
        readOnly: true
      - mountPath: /etc/ca-certificates
        name: etc-ca-certificates
        readOnly: true
      - mountPath: /etc/pki
        name: etc-pki
        readOnly: true
      - mountPath: /etc/kubernetes/pki
        name: k8s-certs
        readOnly: true
      - mountPath: /usr/local/share/ca-certificates
        name: usr-local-share-ca-certificates
        readOnly: true
      - mountPath: /usr/share/ca-certificates
        name: usr-share-ca-certificates
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: ubuntu-host-ddde9b
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/ssl/certs
        type: DirectoryOrCreate
      name: ca-certs
    - hostPath:
        path: /etc/ca-certificates
        type: DirectoryOrCreate
      name: etc-ca-certificates
    - hostPath:
        path: /etc/pki
        type: DirectoryOrCreate
      name: etc-pki
    - hostPath:
        path: /etc/kubernetes/pki
        type: DirectoryOrCreate
      name: k8s-certs
    - hostPath:
        path: /usr/local/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-local-share-ca-certificates
    - hostPath:
        path: /usr/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-share-ca-certificates
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:56:39Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:56:38Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T09:05:09Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T09:05:09Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:56:38Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://c104b778af2b66876322f6b115e20b03bbe07666f6b892b01c6e63f49d2b3e40
      image: registry.k8s.io/kube-apiserver:v1.29.2
      imageID: registry.k8s.io/kube-apiserver@sha256:fe4196cd9fa06bd75b5fb437be89bbccc277e83f3e0296c30b71485ce4834461
      lastState:
        terminated:
          containerID: containerd://9e7bfd78cd5b7dc5c87beb78deb44e259da639a845b84668c72cc6c18943a129
          exitCode: 137
          finishedAt: "2024-03-08T09:04:58Z"
          reason: Error
          startedAt: "2024-03-08T08:28:29Z"
      name: kube-apiserver
      ready: true
      restartCount: 31
      started: true
      state:
        running:
          startedAt: "2024-03-08T09:04:59Z"
    hostIP: 192.168.1.106
    hostIPs:
    - ip: 192.168.1.106
    phase: Running
    podIP: 192.168.1.106
    podIPs:
    - ip: 192.168.1.106
    qosClass: Burstable
    startTime: "2024-03-08T06:56:38Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: af5b894cf9f3fdd4d36259d9b1af3f45
      kubernetes.io/config.mirror: af5b894cf9f3fdd4d36259d9b1af3f45
      kubernetes.io/config.seen: "2024-03-06T21:33:54.422912551+02:00"
      kubernetes.io/config.source: file
    creationTimestamp: "2024-03-06T19:33:54Z"
    labels:
      component: kube-controller-manager
      tier: control-plane
    name: kube-controller-manager-ubuntu-host-ddde9b
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: ubuntu-host-ddde9b
      uid: 8eff4828-5f42-4bc0-a791-84bcdac7502e
    resourceVersion: "208283"
    uid: 0f9be874-efc9-45c5-884d-c278f741f804
  spec:
    containers:
    - command:
      - kube-controller-manager
      - --allocate-node-cidrs=true
      - --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf
      - --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf
      - --bind-address=127.0.0.1
      - --client-ca-file=/etc/kubernetes/pki/ca.crt
      - --cluster-cidr=10.244.0.0/16
      - --cluster-name=kubernetes
      - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt
      - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key
      - --controllers=*,bootstrapsigner,tokencleaner
      - --kubeconfig=/etc/kubernetes/controller-manager.conf
      - --leader-elect=true
      - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
      - --root-ca-file=/etc/kubernetes/pki/ca.crt
      - --service-account-private-key-file=/etc/kubernetes/pki/sa.key
      - --service-cluster-ip-range=10.96.0.0/12
      - --use-service-account-credentials=true
      image: registry.k8s.io/kube-controller-manager:v1.29.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10257
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-controller-manager
      resources:
        requests:
          cpu: 200m
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10257
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: ca-certs
        readOnly: true
      - mountPath: /etc/ca-certificates
        name: etc-ca-certificates
        readOnly: true
      - mountPath: /etc/pki
        name: etc-pki
        readOnly: true
      - mountPath: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
        name: flexvolume-dir
      - mountPath: /etc/kubernetes/pki
        name: k8s-certs
        readOnly: true
      - mountPath: /etc/kubernetes/controller-manager.conf
        name: kubeconfig
        readOnly: true
      - mountPath: /usr/local/share/ca-certificates
        name: usr-local-share-ca-certificates
        readOnly: true
      - mountPath: /usr/share/ca-certificates
        name: usr-share-ca-certificates
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: ubuntu-host-ddde9b
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/ssl/certs
        type: DirectoryOrCreate
      name: ca-certs
    - hostPath:
        path: /etc/ca-certificates
        type: DirectoryOrCreate
      name: etc-ca-certificates
    - hostPath:
        path: /etc/pki
        type: DirectoryOrCreate
      name: etc-pki
    - hostPath:
        path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
        type: DirectoryOrCreate
      name: flexvolume-dir
    - hostPath:
        path: /etc/kubernetes/pki
        type: DirectoryOrCreate
      name: k8s-certs
    - hostPath:
        path: /etc/kubernetes/controller-manager.conf
        type: FileOrCreate
      name: kubeconfig
    - hostPath:
        path: /usr/local/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-local-share-ca-certificates
    - hostPath:
        path: /usr/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-share-ca-certificates
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:56:39Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:56:38Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T09:03:36Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T09:03:36Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:56:38Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://27fc876411978b158adff23eec4477191ab0fe31f0945c3e0a55ca577ee067aa
      image: registry.k8s.io/kube-controller-manager:v1.29.2
      imageID: registry.k8s.io/kube-controller-manager@sha256:4ac9c5b9e65bf9e42e0e9bd40c49d52915b872bf27736606007514bcef53cd93
      lastState:
        terminated:
          containerID: containerd://e047027840f20a0ad82fa7cda644fa5c96abe1085838a86dcf23f7229ae7b357
          exitCode: 1
          finishedAt: "2024-03-08T09:03:26Z"
          reason: Error
          startedAt: "2024-03-08T08:26:54Z"
      name: kube-controller-manager
      ready: true
      restartCount: 26
      started: true
      state:
        running:
          startedAt: "2024-03-08T09:03:26Z"
    hostIP: 192.168.1.106
    hostIPs:
    - ip: 192.168.1.106
    phase: Running
    podIP: 192.168.1.106
    podIPs:
    - ip: 192.168.1.106
    qosClass: Burstable
    startTime: "2024-03-08T06:56:38Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-03-06T19:54:32Z"
    generateName: kube-proxy-
    labels:
      controller-revision-hash: 65bbdcdfff
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-5b6dx
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: e4cacdb6-67d7-47bd-9628-1e047ccb6ff5
    resourceVersion: "196308"
    uid: 14aad1f9-45c7-4fd3-b687-58ab164639dc
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ubuntu-host-75e4c5
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      - --hostname-override=$(NODE_NAME)
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: registry.k8s.io/kube-proxy:v1.29.2
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-cxvdd
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: ubuntu-host-75e4c5
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-api-access-cxvdd
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:57:06Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-03-06T19:54:33Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:57:19Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:57:19Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-06T19:54:32Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://413f999d986a35cff3af284fa07191c776d6dec90dc004ff43c60a589b83b314
      image: registry.k8s.io/kube-proxy:v1.29.2
      imageID: registry.k8s.io/kube-proxy@sha256:4a993783f8b8d6ec00281dd0bc334712fd7007316709f086a4a48bf250d24d08
      lastState:
        terminated:
          containerID: containerd://a658704eca87289c94a20cdc9a5d3b29e7d4c0097cbcaa74c425c5254eaa6c84
          exitCode: 255
          finishedAt: "2023-09-19T17:00:05Z"
          reason: Unknown
          startedAt: "2024-03-06T19:54:53Z"
      name: kube-proxy
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-03-08T06:57:18Z"
    hostIP: 192.168.1.100
    hostIPs:
    - ip: 192.168.1.100
    phase: Running
    podIP: 192.168.1.100
    podIPs:
    - ip: 192.168.1.100
    qosClass: BestEffort
    startTime: "2024-03-06T19:54:33Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-03-06T19:55:54Z"
    generateName: kube-proxy-
    labels:
      controller-revision-hash: 65bbdcdfff
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-8kxxl
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: e4cacdb6-67d7-47bd-9628-1e047ccb6ff5
    resourceVersion: "196335"
    uid: 79ebbbc5-21af-48bd-9828-9e233778b422
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ubuntu-host-76d48b
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      - --hostname-override=$(NODE_NAME)
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: registry.k8s.io/kube-proxy:v1.29.2
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bzrm9
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: ubuntu-host-76d48b
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-api-access-bzrm9
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:57:06Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-03-06T19:55:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:57:22Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:57:22Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-06T19:55:55Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://f4bff5b4bbec0cf9e39f342b06756ba156aae44385cedb03c1e3b8ec42c09c84
      image: registry.k8s.io/kube-proxy:v1.29.2
      imageID: registry.k8s.io/kube-proxy@sha256:4a993783f8b8d6ec00281dd0bc334712fd7007316709f086a4a48bf250d24d08
      lastState:
        terminated:
          containerID: containerd://53b54830c0b0030674b1a5f4f64785f59ae9d5e461b34045689f27c1516c320b
          exitCode: 255
          finishedAt: "2023-09-19T17:00:07Z"
          reason: Unknown
          startedAt: "2024-03-06T19:56:11Z"
      name: kube-proxy
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-03-08T06:57:22Z"
    hostIP: 192.168.1.101
    hostIPs:
    - ip: 192.168.1.101
    phase: Running
    podIP: 192.168.1.101
    podIPs:
    - ip: 192.168.1.101
    qosClass: BestEffort
    startTime: "2024-03-06T19:55:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-03-06T20:01:19Z"
    generateName: kube-proxy-
    labels:
      controller-revision-hash: 65bbdcdfff
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-d6rg7
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: e4cacdb6-67d7-47bd-9628-1e047ccb6ff5
    resourceVersion: "196263"
    uid: f20d6609-e1b1-41dc-93a0-dff5b4dead0b
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ubuntu-host-a6773f
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      - --hostname-override=$(NODE_NAME)
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: registry.k8s.io/kube-proxy:v1.29.2
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-x2xqz
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: ubuntu-host-a6773f
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-api-access-x2xqz
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:57:10Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-03-06T20:01:20Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:57:10Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:57:10Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-06T20:01:19Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://886ca4abdd66f62b31ec42bab91152b3c1802178db7895c9a57db8ced0694279
      image: registry.k8s.io/kube-proxy:v1.29.2
      imageID: registry.k8s.io/kube-proxy@sha256:4a993783f8b8d6ec00281dd0bc334712fd7007316709f086a4a48bf250d24d08
      lastState:
        terminated:
          containerID: containerd://781fd98ab515c8059fc98a26677df1a12f91e904bbe8ef2e9560c6a3952678ac
          exitCode: 255
          finishedAt: "2023-09-19T17:00:04Z"
          reason: Unknown
          startedAt: "2024-03-06T20:01:34Z"
      name: kube-proxy
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-03-08T06:57:09Z"
    hostIP: 192.168.1.102
    hostIPs:
    - ip: 192.168.1.102
    phase: Running
    podIP: 192.168.1.102
    podIPs:
    - ip: 192.168.1.102
    qosClass: BestEffort
    startTime: "2024-03-06T20:01:20Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-03-06T19:34:09Z"
    generateName: kube-proxy-
    labels:
      controller-revision-hash: 65bbdcdfff
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-rsjkc
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: e4cacdb6-67d7-47bd-9628-1e047ccb6ff5
    resourceVersion: "196117"
    uid: 1a7e472f-d936-435b-bb05-268ca861daa0
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ubuntu-host-ddde9b
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      - --hostname-override=$(NODE_NAME)
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: registry.k8s.io/kube-proxy:v1.29.2
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xlj46
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: ubuntu-host-ddde9b
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-api-access-xlj46
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:56:43Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-03-06T19:34:09Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:56:43Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:56:43Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-06T19:34:09Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://fd336926254d5427960d4a260fd0d381b967b12792cadb65af478a9b4b77aec8
      image: registry.k8s.io/kube-proxy:v1.29.2
      imageID: registry.k8s.io/kube-proxy@sha256:4a993783f8b8d6ec00281dd0bc334712fd7007316709f086a4a48bf250d24d08
      lastState:
        terminated:
          containerID: containerd://a10fde55f9d3a593ef6f3b97d7a00cc90bbdd7dd26e352aa0265ec36b2f2f71b
          exitCode: 255
          finishedAt: "2024-03-08T06:53:39Z"
          reason: Unknown
          startedAt: "2024-03-06T19:46:19Z"
      name: kube-proxy
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2024-03-08T06:56:42Z"
    hostIP: 192.168.1.106
    hostIPs:
    - ip: 192.168.1.106
    phase: Running
    podIP: 192.168.1.106
    podIPs:
    - ip: 192.168.1.106
    qosClass: BestEffort
    startTime: "2024-03-06T19:34:09Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: bf0357f363d1a632a1cd9e6124fbcdeb
      kubernetes.io/config.mirror: bf0357f363d1a632a1cd9e6124fbcdeb
      kubernetes.io/config.seen: "2024-03-06T21:33:49.229092866+02:00"
      kubernetes.io/config.source: file
    creationTimestamp: "2024-03-06T19:33:52Z"
    labels:
      component: kube-scheduler
      tier: control-plane
    name: kube-scheduler-ubuntu-host-ddde9b
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: ubuntu-host-ddde9b
      uid: 8eff4828-5f42-4bc0-a791-84bcdac7502e
    resourceVersion: "208278"
    uid: f94ad5fd-9f4f-4ffc-9256-c52d86a389b1
  spec:
    containers:
    - command:
      - kube-scheduler
      - --authentication-kubeconfig=/etc/kubernetes/scheduler.conf
      - --authorization-kubeconfig=/etc/kubernetes/scheduler.conf
      - --bind-address=127.0.0.1
      - --kubeconfig=/etc/kubernetes/scheduler.conf
      - --leader-elect=true
      image: registry.k8s.io/kube-scheduler:v1.29.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10259
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-scheduler
      resources:
        requests:
          cpu: 100m
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10259
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/kubernetes/scheduler.conf
        name: kubeconfig
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: ubuntu-host-ddde9b
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/scheduler.conf
        type: FileOrCreate
      name: kubeconfig
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:56:39Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:56:38Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T09:03:41Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T09:03:41Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-03-08T06:56:38Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://c4e0e491a422a5e7624443856eb44781891ed5263c5d2105fa6c05afe25ce6f4
      image: registry.k8s.io/kube-scheduler:v1.29.2
      imageID: registry.k8s.io/kube-scheduler@sha256:108e51c8bcd2dcbd56462ef0d08a915bb19d956ad8bce167b6a2834ca92fe08f
      lastState:
        terminated:
          containerID: containerd://101e29319a193b7de6b67dc213bf4c139271388fa362075241b72eaaa4350f14
          exitCode: 1
          finishedAt: "2024-03-08T09:03:30Z"
          reason: Error
          startedAt: "2024-03-08T08:27:00Z"
      name: kube-scheduler
      ready: true
      restartCount: 28
      started: true
      state:
        running:
          startedAt: "2024-03-08T09:03:30Z"
    hostIP: 192.168.1.106
    hostIPs:
    - ip: 192.168.1.106
    phase: Running
    podIP: 192.168.1.106
    podIPs:
    - ip: 192.168.1.106
    qosClass: Burstable
    startTime: "2024-03-08T06:56:38Z"
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2024-03-06T19:33:52Z"
    labels:
      component: apiserver
      provider: kubernetes
    name: kubernetes
    namespace: default
    resourceVersion: "196"
    uid: 17c0a55d-4ec8-45b3-ace1-4fcac5565489
  spec:
    clusterIP: 10.96.0.1
    clusterIPs:
    - 10.96.0.1
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: https
      port: 443
      protocol: TCP
      targetPort: 6443
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      prometheus.io/port: "9153"
      prometheus.io/scrape: "true"
    creationTimestamp: "2024-03-06T19:33:54Z"
    labels:
      k8s-app: kube-dns
      kubernetes.io/cluster-service: "true"
      kubernetes.io/name: CoreDNS
    name: kube-dns
    namespace: kube-system
    resourceVersion: "226"
    uid: 49e77e9d-65e4-4f33-ac6c-701fe9393219
  spec:
    clusterIP: 10.96.0.10
    clusterIPs:
    - 10.96.0.10
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: dns
      port: 53
      protocol: UDP
      targetPort: 53
    - name: dns-tcp
      port: 53
      protocol: TCP
      targetPort: 53
    - name: metrics
      port: 9153
      protocol: TCP
      targetPort: 9153
    selector:
      k8s-app: kube-dns
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"app":"flannel","k8s-app":"flannel","tier":"node"},"name":"kube-flannel-ds","namespace":"kube-flannel"},"spec":{"selector":{"matchLabels":{"app":"flannel","k8s-app":"flannel"}},"template":{"metadata":{"labels":{"app":"flannel","k8s-app":"flannel","tier":"node"}},"spec":{"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchExpressions":[{"key":"kubernetes.io/os","operator":"In","values":["linux"]}]}]}}},"containers":[{"args":["--ip-masq","--kube-subnet-mgr"],"command":["/opt/bin/flanneld"],"env":[{"name":"POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}},{"name":"EVENT_QUEUE_DEPTH","value":"5000"}],"image":"docker.io/flannel/flannel:v0.24.3","name":"kube-flannel","resources":{"requests":{"cpu":"100m","memory":"50Mi"}},"securityContext":{"capabilities":{"add":["NET_ADMIN","NET_RAW"]},"privileged":false},"volumeMounts":[{"mountPath":"/run/flannel","name":"run"},{"mountPath":"/etc/kube-flannel/","name":"flannel-cfg"},{"mountPath":"/run/xtables.lock","name":"xtables-lock"}]}],"hostNetwork":true,"initContainers":[{"args":["-f","/flannel","/opt/cni/bin/flannel"],"command":["cp"],"image":"docker.io/flannel/flannel-cni-plugin:v1.4.0-flannel1","name":"install-cni-plugin","volumeMounts":[{"mountPath":"/opt/cni/bin","name":"cni-plugin"}]},{"args":["-f","/etc/kube-flannel/cni-conf.json","/etc/cni/net.d/10-flannel.conflist"],"command":["cp"],"image":"docker.io/flannel/flannel:v0.24.3","name":"install-cni","volumeMounts":[{"mountPath":"/etc/cni/net.d","name":"cni"},{"mountPath":"/etc/kube-flannel/","name":"flannel-cfg"}]}],"priorityClassName":"system-node-critical","serviceAccountName":"flannel","tolerations":[{"effect":"NoSchedule","operator":"Exists"}],"volumes":[{"hostPath":{"path":"/run/flannel"},"name":"run"},{"hostPath":{"path":"/opt/cni/bin"},"name":"cni-plugin"},{"hostPath":{"path":"/etc/cni/net.d"},"name":"cni"},{"configMap":{"name":"kube-flannel-cfg"},"name":"flannel-cfg"},{"hostPath":{"path":"/run/xtables.lock","type":"FileOrCreate"},"name":"xtables-lock"}]}}}}
    creationTimestamp: "2024-03-06T19:49:35Z"
    generation: 1
    labels:
      app: flannel
      k8s-app: flannel
      tier: node
    name: kube-flannel-ds
    namespace: kube-flannel
    resourceVersion: "196354"
    uid: 423cf737-db9a-4d60-9b62-e52dce100d67
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: flannel
        k8s-app: flannel
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: flannel
          k8s-app: flannel
          tier: node
      spec:
        affinity:
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: kubernetes.io/os
                  operator: In
                  values:
                  - linux
        containers:
        - args:
          - --ip-masq
          - --kube-subnet-mgr
          command:
          - /opt/bin/flanneld
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: EVENT_QUEUE_DEPTH
            value: "5000"
          image: docker.io/flannel/flannel:v0.24.3
          imagePullPolicy: IfNotPresent
          name: kube-flannel
          resources:
            requests:
              cpu: 100m
              memory: 50Mi
          securityContext:
            capabilities:
              add:
              - NET_ADMIN
              - NET_RAW
            privileged: false
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /run/flannel
            name: run
          - mountPath: /etc/kube-flannel/
            name: flannel-cfg
          - mountPath: /run/xtables.lock
            name: xtables-lock
        dnsPolicy: ClusterFirst
        hostNetwork: true
        initContainers:
        - args:
          - -f
          - /flannel
          - /opt/cni/bin/flannel
          command:
          - cp
          image: docker.io/flannel/flannel-cni-plugin:v1.4.0-flannel1
          imagePullPolicy: IfNotPresent
          name: install-cni-plugin
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /opt/cni/bin
            name: cni-plugin
        - args:
          - -f
          - /etc/kube-flannel/cni-conf.json
          - /etc/cni/net.d/10-flannel.conflist
          command:
          - cp
          image: docker.io/flannel/flannel:v0.24.3
          imagePullPolicy: IfNotPresent
          name: install-cni
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/cni/net.d
            name: cni
          - mountPath: /etc/kube-flannel/
            name: flannel-cfg
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: flannel
        serviceAccountName: flannel
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          operator: Exists
        volumes:
        - hostPath:
            path: /run/flannel
            type: ""
          name: run
        - hostPath:
            path: /opt/cni/bin
            type: ""
          name: cni-plugin
        - hostPath:
            path: /etc/cni/net.d
            type: ""
          name: cni
        - configMap:
            defaultMode: 420
            name: kube-flannel-cfg
          name: flannel-cfg
        - hostPath:
            path: /run/xtables.lock
            type: FileOrCreate
          name: xtables-lock
    updateStrategy:
      rollingUpdate:
        maxSurge: 0
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 4
    desiredNumberScheduled: 4
    numberAvailable: 4
    numberMisscheduled: 0
    numberReady: 4
    observedGeneration: 1
    updatedNumberScheduled: 4
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
    creationTimestamp: "2024-03-06T19:33:54Z"
    generation: 1
    labels:
      k8s-app: kube-proxy
    name: kube-proxy
    namespace: kube-system
    resourceVersion: "196336"
    uid: e4cacdb6-67d7-47bd-9628-1e047ccb6ff5
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: kube-proxy
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: kube-proxy
      spec:
        containers:
        - command:
          - /usr/local/bin/kube-proxy
          - --config=/var/lib/kube-proxy/config.conf
          - --hostname-override=$(NODE_NAME)
          env:
          - name: NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          image: registry.k8s.io/kube-proxy:v1.29.2
          imagePullPolicy: IfNotPresent
          name: kube-proxy
          resources: {}
          securityContext:
            privileged: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/lib/kube-proxy
            name: kube-proxy
          - mountPath: /run/xtables.lock
            name: xtables-lock
          - mountPath: /lib/modules
            name: lib-modules
            readOnly: true
        dnsPolicy: ClusterFirst
        hostNetwork: true
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: kube-proxy
        serviceAccountName: kube-proxy
        terminationGracePeriodSeconds: 30
        tolerations:
        - operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: kube-proxy
          name: kube-proxy
        - hostPath:
            path: /run/xtables.lock
            type: FileOrCreate
          name: xtables-lock
        - hostPath:
            path: /lib/modules
            type: ""
          name: lib-modules
    updateStrategy:
      rollingUpdate:
        maxSurge: 0
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 4
    desiredNumberScheduled: 4
    numberAvailable: 4
    numberMisscheduled: 0
    numberReady: 4
    observedGeneration: 1
    updatedNumberScheduled: 4
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-03-06T19:33:54Z"
    generation: 1
    labels:
      k8s-app: kube-dns
    name: coredns
    namespace: kube-system
    resourceVersion: "208380"
    uid: d4d44d93-a4ad-4002-9558-84dec7622278
  spec:
    progressDeadlineSeconds: 600
    replicas: 2
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: kube-dns
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: kube-dns
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: k8s-app
                    operator: In
                    values:
                    - kube-dns
                topologyKey: kubernetes.io/hostname
              weight: 100
        containers:
        - args:
          - -conf
          - /etc/coredns/Corefile
          image: registry.k8s.io/coredns/coredns:v1.11.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /health
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: coredns
          ports:
          - containerPort: 53
            name: dns
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 9153
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /ready
              port: 8181
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              memory: 170Mi
            requests:
              cpu: 100m
              memory: 70Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/coredns
            name: config-volume
            readOnly: true
        dnsPolicy: Default
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: coredns
        serviceAccountName: coredns
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
        volumes:
        - configMap:
            defaultMode: 420
            items:
            - key: Corefile
              path: Corefile
            name: coredns
          name: config-volume
  status:
    availableReplicas: 2
    conditions:
    - lastTransitionTime: "2024-03-06T19:49:59Z"
      lastUpdateTime: "2024-03-06T19:49:59Z"
      message: ReplicaSet "coredns-76f75df574" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2024-03-08T09:05:40Z"
      lastUpdateTime: "2024-03-08T09:05:40Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 2
    replicas: 2
    updatedReplicas: 2
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "2"
      deployment.kubernetes.io/max-replicas: "3"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-03-06T19:34:09Z"
    generation: 1
    labels:
      k8s-app: kube-dns
      pod-template-hash: 76f75df574
    name: coredns-76f75df574
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: coredns
      uid: d4d44d93-a4ad-4002-9558-84dec7622278
    resourceVersion: "208379"
    uid: 4eb85c37-d82e-4b19-9434-ba01cbb04931
  spec:
    replicas: 2
    selector:
      matchLabels:
        k8s-app: kube-dns
        pod-template-hash: 76f75df574
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: kube-dns
          pod-template-hash: 76f75df574
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: k8s-app
                    operator: In
                    values:
                    - kube-dns
                topologyKey: kubernetes.io/hostname
              weight: 100
        containers:
        - args:
          - -conf
          - /etc/coredns/Corefile
          image: registry.k8s.io/coredns/coredns:v1.11.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /health
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: coredns
          ports:
          - containerPort: 53
            name: dns
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 9153
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /ready
              port: 8181
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              memory: 170Mi
            requests:
              cpu: 100m
              memory: 70Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/coredns
            name: config-volume
            readOnly: true
        dnsPolicy: Default
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: coredns
        serviceAccountName: coredns
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
        volumes:
        - configMap:
            defaultMode: 420
            items:
            - key: Corefile
              path: Corefile
            name: coredns
          name: config-volume
  status:
    availableReplicas: 2
    fullyLabeledReplicas: 2
    observedGeneration: 1
    readyReplicas: 2
    replicas: 2
kind: List
metadata:
  resourceVersion: ""
